# Module vtab/&zwnj;relative-patch-location/1
Visual representation obtained by predicting relative patch location on ImageNet.

<!-- asset-path: https://storage.googleapis.com/vtab/relative-patch-location/1.tar.gz -->
<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: ResNet50-v2 -->
<!-- fine-tunable: true -->
<!-- format: hub -->


## Overview
ResNet50-v2 trained by using the relative path location prediction
self-supervsed loss [1], trained on ImageNet [2].

#### Usage

```python
module = hub.Module("https://tfhub.dev/vtab/relative-patch-location/1")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
features = module(images)  # Features with shape [batch_size, num_features].
```

The input `images` are expected to have color values in the range [0,1], following
the [common image input](https://www.tensorflow.org/hub/common_signatures/images#input) conventions.
This module is suitable to be fine tuned.

#### References
[1] Carl Doersch, Abhinav Gupta, and Alexei A Efros.
[Unsupervised Visual Representation Learning by Context Prediction](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Doersch_Unsupervised_Visual_Representation_ICCV_2015_paper.pdf).
In IEEE International Conference on Computer Vision, 2015.

[2] Alexander Kolesnikov, Xiaohua Zhai, and Lucas Beyer.
[Revisiting Self-Supervised Visual Representation Learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.pdf).
In IEEE Conference on Computer Vision and Pattern Recognition, 2019.
