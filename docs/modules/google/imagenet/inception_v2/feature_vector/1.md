# Module google/&zwnj;imagenet/&zwnj;inception_v2/&zwnj;feature_vector/1

**Module URL:** [https://tfhub.dev/google/imagenet/inception_v2/feature_vector/1](https://tfhub.dev/google/imagenet/inception_v2/feature_vector/1)

## Overview

Inception V2 is a neural network architecture for image classification.
It builds on the Inception architecture originally published by

  * Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke and Andrew Rabinovich:
    ["Going deeper with convolutions"](https://arxiv.org/abs/1409.4842), 2014.

Inception V2 uses are more powerful architecture made possible by
the use of batch normalization. Both were introduced by

  * Sergey Ioffe and Christian Szegedy: [Batch Normalization:
    Accelerating Deep Network Training by Reducing Internal Covariate
    Shift](https://arxiv.org/abs/1502.03167), 2015.

This TF-Hub module uses the TF-Slim implementation of `inception_v2`.
The module contains a trained instance of the network, packaged to get
[feature vectors from images](../../../../../common_signatures/images.md#feature-vector).
If you want the full model including the classification it was originally
trained for, use module
[`google/imagenet/inception_v2/classification/1`](../classification/1.md)
instead.


## Training

The checkpoint exported into this module was `inception_v2_2016_08_28/inception_v2.ckpt` downloaded
from
[TF-Slim's pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/README.md#pre-trained-models).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet").


## Usage

This module implements the common signature for computing
[image feature vectors](../../../../../common_signatures/images.md#feature-vector).
It can be used like

```python
module = hub.Module("https://tfhub.dev/google/imagenet/inception_v2/feature_vector/1")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
features = module(images)  # Features with shape [batch_size, num_features].
```

...or using the signature name `image_feature_vector`. The output for each image
in the batch is a feature vector of size `num_features` = 1024.

For this module, the size of the input image is fixed to
`height` x `width` = 224 x 224 pixels.
The input `images` are expected to have color values in the range [0,1],
following the
[common image input](../../../../../common_signatures/images.md#input)
conventions.


## Fine-tuning

Consumers of this module can [fine-tune](../../../../../fine_tuning.md) it.
This requires importing the graph version with tag set `{"train"}`
in order to operate batch normalization in training mode.

