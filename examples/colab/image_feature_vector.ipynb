{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning with TensorFlow",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ScitaPqhKtuW"
      ]
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ScitaPqhKtuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "bNnChGfZK2_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Z_ZvMk5JPFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow\n",
        "\n",
        "<table align=\"left\">\n",
        "<td align=\"center\">\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/image_feature_vector.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /><br>Run in Google Colab\n",
        "  </a>\n",
        "</td>\n",
        "<td align=\"center\">\n",
        "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/image_feature_vector.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /><br>View source on GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "gh-LWtlqLtgH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Have you ever seen a beautiful flower and wondered what kind of flower it is? Well, you're not the first, so let's build a way to identify the type of flower from a photo!\n",
        "\n",
        "For classifying images, a particular type of *deep neural network*, called a *convolutional neural network* has proved to be particularly powerful. However, modern convolutional neural networks have millions of parameters. Training them from scratch requires a lot of labeled training data and a lot of computing power (hundreds of GPU-hours or more). We only have about three thousand labeled photos and want to spend much less time, so we need to be more clever.\n",
        "\n",
        "We will use a technique called *transfer learning* where we take a pre-trained network (trained on about a million general images), use it to extract features, and train a new layer on top for our own task of classifying images of flowers.\n",
        "\n",
        "## Colab Setup\n",
        "\n",
        "Click on the \"Connect\" dropdown on the top right and click \"Connect to hosted runtime\"\n",
        "\n",
        "If you haven't worked with Colab before, then use `Ctrl+Shift+P` to show the command palette. The most important command is `Shift+Enter`, which runs the current cell and moves to the next one. Try it on the following cell with imports:"
      ]
    },
    {
      "metadata": {
        "id": "NTrs9zBKJK1c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from six.moves import urllib\n",
        "\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "from StringIO import StringIO\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as sk_metrics\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Do-T63G7NCSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The flowers dataset\n",
        "\n",
        "The flowers dataset consists of images of flowers with 5 possible class labels.\n",
        "\n",
        "When training a machine learning model, we split our data into training and test datasets. We will train the model on our training data and then evaluate how well the model performs on data it has never seen - the test set.\n",
        "\n",
        "Let's download our training and test examples (it may take a while) and split them into train and test sets.\n",
        "\n",
        "Run the following two cells:"
      ]
    },
    {
      "metadata": {
        "id": "HYQr1SILIxSK",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Define some helper functions [RUN ME!]\n",
        "FLOWERS_DIR = './flower_photos'\n",
        "TRAIN_FRACTION = 0.8\n",
        "RANDOM_SEED = 2018\n",
        "\n",
        "\n",
        "def download_images():\n",
        "  \"\"\"If the images aren't already downloaded, save them to FLOWERS_DIR.\"\"\"\n",
        "  if not os.path.exists(FLOWERS_DIR):\n",
        "    DOWNLOAD_URL = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "    print('Downloading flower images from %s...' % DOWNLOAD_URL)\n",
        "    urllib.request.urlretrieve(DOWNLOAD_URL, 'flower_photos.tgz')\n",
        "    !tar xfz flower_photos.tgz\n",
        "  print('Flower photos are located in %s' % FLOWERS_DIR)\n",
        "\n",
        "\n",
        "def make_train_and_test_sets():\n",
        "  \"\"\"Split the data into train and test sets and get the label classes.\"\"\"\n",
        "  train_examples, test_examples = [], []\n",
        "  shuffler = random.Random(RANDOM_SEED)\n",
        "  is_root = True\n",
        "  for (dirname, subdirs, filenames) in tf.gfile.Walk(FLOWERS_DIR):\n",
        "    # The root directory gives us the classes\n",
        "    if is_root:\n",
        "      subdirs = sorted(subdirs)\n",
        "      classes = collections.OrderedDict(enumerate(subdirs))\n",
        "      label_to_class = dict([(x, i) for i, x in enumerate(subdirs)])\n",
        "      is_root = False\n",
        "    # The sub directories give us the image files for training.\n",
        "    else:\n",
        "      filenames.sort()\n",
        "      shuffler.shuffle(filenames)\n",
        "      full_filenames = [os.path.join(dirname, f) for f in filenames]\n",
        "      label = dirname.split('/')[-1]\n",
        "      label_class = label_to_class[label]\n",
        "      # An example is the image file and it's label class.\n",
        "      examples = zip(full_filenames, [label_class] * len(filenames))\n",
        "      num_train = int(len(filenames) * TRAIN_FRACTION)\n",
        "      train_examples.extend(examples[:num_train])\n",
        "      test_examples.extend(examples[num_train:])\n",
        "\n",
        "  shuffler.shuffle(train_examples)\n",
        "  shuffler.shuffle(test_examples)\n",
        "  return train_examples, test_examples, classes\n",
        "\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for node in graph_def.node:\n",
        "        stripped_node = strip_def.node.add()\n",
        "        stripped_node.MergeFrom(node)\n",
        "        if stripped_node.op == 'Const':\n",
        "            tensor = stripped_node.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
        "    return strip_def\n",
        "\n",
        "\n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "\n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9NklpcANhtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download the images and split the images into train and test sets.\n",
        "download_images()\n",
        "TRAIN_EXAMPLES, TEST_EXAMPLES, CLASSES = make_train_and_test_sets()\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print('\\nThe dataset has %d label classes: %s' % (NUM_CLASSES, CLASSES.values()))\n",
        "print('There are %d training images' % len(TRAIN_EXAMPLES))\n",
        "print('there are %d test images' % len(TEST_EXAMPLES))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHF7bHTfnD6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Explore the data\n",
        "\n",
        "The flowers dataset consists of examples which are labeled images of flowers. Each example contains a JPEG flower image and the class label: what type of flower it is. Let's display a few images together with their labels."
      ]
    },
    {
      "metadata": {
        "id": "1friUvN6kPYM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Show some labeled images\n",
        "def get_label(example):\n",
        "  \"\"\"Get the label (number) for given example.\"\"\"\n",
        "  return example[1]\n",
        "\n",
        "def get_class(example):\n",
        "  \"\"\"Get the class (string) of given example.\"\"\"\n",
        "  return CLASSES[get_label(example)]\n",
        "\n",
        "def get_encoded_image(example):\n",
        "  \"\"\"Get the image data (encoded jpg) of given example.\"\"\"\n",
        "  image_path = example[0]\n",
        "  return tf.gfile.FastGFile(image_path, 'rb').read()\n",
        "\n",
        "def get_image(example):\n",
        "  \"\"\"Get image as np.array of pixels for given example.\"\"\"\n",
        "  return plt.imread(StringIO(get_encoded_image(example)), format='jpg')\n",
        "\n",
        "def display_images(images_and_classes, cols=5):\n",
        "  \"\"\"Display given images and their labels in a grid.\"\"\"\n",
        "  rows = int(math.ceil(len(images_and_classes) / cols))\n",
        "  fig = plt.figure()\n",
        "  fig.set_size_inches(cols * 3, rows * 3)\n",
        "  for i, (image, flower_class) in enumerate(images_and_classes):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    plt.title(flower_class)\n",
        "\n",
        "NUM_IMAGES = 15 #@param {type: 'integer'}\n",
        "display_images([(get_image(example), get_class(example))\n",
        "               for example in TRAIN_EXAMPLES[:NUM_IMAGES]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hyjr6PuboTAg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "We will load a [TF-Hub](https://tensorflow.org/hub) image feature vector module, stack a linear classifier on it, and add training and evaluation ops. The following cell builds a TF graph describing the model and its training, but it doesn't run the training (that will be the next step)."
      ]
    },
    {
      "metadata": {
        "id": "LbkSRaK_oW5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 0.01\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Load a pre-trained TF-Hub module for extracting features from images. We've\n",
        "# chosen this particular module for speed, but many other choices are available.\n",
        "image_module = hub.Module('https://tfhub.dev/google/imagenet/mobilenet_v2_035_128/feature_vector/2')\n",
        "\n",
        "# Preprocessing images into tensors with size expected by the image module.\n",
        "encoded_images = tf.placeholder(tf.string, shape=[None])\n",
        "image_size = hub.get_expected_image_size(image_module)\n",
        "\n",
        "\n",
        "def decode_and_resize_image(encoded):\n",
        "  decoded = tf.image.decode_jpeg(encoded, channels=3)\n",
        "  decoded = tf.image.convert_image_dtype(decoded, tf.float32)\n",
        "  return tf.image.resize_images(decoded, image_size)\n",
        "\n",
        "\n",
        "batch_images = tf.map_fn(decode_and_resize_image, encoded_images, dtype=tf.float32)\n",
        "\n",
        "# The image module can be applied as a function to extract feature vectors for a\n",
        "# batch of images.\n",
        "features = image_module(batch_images)\n",
        "\n",
        "\n",
        "def create_model(features):\n",
        "  \"\"\"Build a model for classification from extracted features.\"\"\"\n",
        "  # Currently, the model is just a single linear layer. You can try to add\n",
        "  # another layer, but be careful... two linear layers (when activation=None)\n",
        "  # are equivalent to a single linear layer. You can create a nonlinear layer\n",
        "  # like this:\n",
        "  # layer = tf.layers.dense(inputs=..., units=..., activation=tf.nn.relu)\n",
        "  layer = tf.layers.dense(inputs=features, units=NUM_CLASSES, activation=None)\n",
        "  return layer\n",
        "\n",
        "\n",
        "# For each class (kind of flower), the model outputs some real number as a score\n",
        "# how much the input resembles this class. This vector of numbers is often\n",
        "# called the \"logits\".\n",
        "logits = create_model(features)\n",
        "labels = tf.placeholder(tf.float32, [None, NUM_CLASSES])\n",
        "\n",
        "# Mathematically, a good way to measure how much the predicted probabilities\n",
        "# diverge from the truth is the \"cross-entropy\" between the two probability\n",
        "# distributions. For numerical stability, this is best done directly from the\n",
        "# logits, not the probabilities extracted from them.\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
        "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "# Let's add an optimizer so we can train the network.\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
        "train_op = optimizer.minimize(loss=cross_entropy_mean)\n",
        "\n",
        "# The \"softmax\" function transforms the logits vector into a vector of\n",
        "# probabilities: non-negative numbers that sum up to one, and the i-th number\n",
        "# says how likely the input comes from class i.\n",
        "probabilities = tf.nn.softmax(logits)\n",
        "\n",
        "# We choose the highest one as the predicted class.\n",
        "prediction = tf.argmax(probabilities, 1)\n",
        "correct_prediction = tf.equal(prediction, tf.argmax(labels, 1))\n",
        "\n",
        "# The accuracy will allow us to eval on our test set. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Show the created TF graph.\n",
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vvhYQ7-3AG_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the network\n",
        "\n",
        "Now that our model is built, let's train it and see how it perfoms on our test set."
      ]
    },
    {
      "metadata": {
        "id": "1YnBg7-OS3Dz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# How long will we train the network (number of batches).\n",
        "NUM_TRAIN_STEPS = 100 #@param {type: 'integer'}\n",
        "# How many training examples we use in each step.\n",
        "TRAIN_BATCH_SIZE = 10 #@param {type: 'integer'}\n",
        "# How often to evaluate the model performance.\n",
        "EVAL_EVERY = 10 #@param {type: 'integer'}\n",
        "\n",
        "def get_batch(batch_size=None, test=False):\n",
        "  \"\"\"Get a random batch of examples.\"\"\"\n",
        "  examples = TEST_EXAMPLES if test else TRAIN_EXAMPLES\n",
        "  batch_examples = random.sample(examples, batch_size) if batch_size else examples\n",
        "  return batch_examples\n",
        "\n",
        "def get_images_and_labels(batch_examples):\n",
        "  images = [get_encoded_image(e) for e in batch_examples]\n",
        "  one_hot_labels = [get_label_one_hot(e) for e in batch_examples]\n",
        "  return images, one_hot_labels\n",
        "\n",
        "def get_label_one_hot(example):\n",
        "  \"\"\"Get the one hot encoding vector for the example.\"\"\"\n",
        "  one_hot_vector = np.zeros(NUM_CLASSES)\n",
        "  np.put(one_hot_vector, get_label(example), 1)\n",
        "  return one_hot_vector\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for i in range(NUM_TRAIN_STEPS):\n",
        "    # Get a random batch of training examples.\n",
        "    train_batch = get_batch(batch_size=TRAIN_BATCH_SIZE)\n",
        "    batch_images, batch_labels = get_images_and_labels(train_batch)\n",
        "    # Run the train_op to train the model.\n",
        "    train_loss, _, train_accuracy = sess.run(\n",
        "        [cross_entropy_mean, train_op, accuracy],\n",
        "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
        "    is_final_step = (i == (NUM_TRAIN_STEPS - 1))\n",
        "    if i % EVAL_EVERY == 0 or is_final_step:\n",
        "      # Get a batch of test examples.\n",
        "      test_batch = get_batch(batch_size=None, test=True)\n",
        "      batch_images, batch_labels = get_images_and_labels(test_batch)\n",
        "      # Evaluate how well our model performs on the test set.\n",
        "      test_loss, test_accuracy, test_prediction, correct_predicate = sess.run(\n",
        "        [cross_entropy_mean, accuracy, prediction, correct_prediction],\n",
        "        feed_dict={encoded_images: batch_images, labels: batch_labels})\n",
        "      print('Test accuracy at step %s: %.2f%%' % (i, (test_accuracy * 100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFUNJxuH2t0V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_confusion_matrix(test_labels, predictions):\n",
        "  \"\"\"Compute confusion matrix and normalize.\"\"\"\n",
        "  confusion = sk_metrics.confusion_matrix(\n",
        "    np.argmax(test_labels, axis=1), predictions)\n",
        "  confusion_normalized = confusion.astype(\"float\") / confusion.sum(axis=1)\n",
        "  axis_labels = CLASSES.values()\n",
        "  ax = sns.heatmap(\n",
        "      confusion_normalized, xticklabels=axis_labels, yticklabels=axis_labels,\n",
        "      cmap='Blues', annot=True, fmt='.2f', square=True)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel(\"Predicted label\")\n",
        "\n",
        "show_confusion_matrix(batch_labels, test_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uu3vo8DK8BdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Incorrect predictions\n",
        "\n",
        "Let's a take a closer look at the test examples that our model got wrong.\n",
        "\n",
        "- Are there any mislabeled examples in our test set?\n",
        "- Is there any bad data in the test set - images that aren't actually pictures of flowers?\n",
        "- Are there images where you can understand why the model made a mistake?"
      ]
    },
    {
      "metadata": {
        "id": "hqa0V3WN8C9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "incorrect = [\n",
        "    (example, CLASSES[prediction])\n",
        "    for example, prediction, is_correct in zip(test_batch, test_prediction, correct_predicate)\n",
        "    if not is_correct\n",
        "]\n",
        "display_images(\n",
        "  [(get_image(example), \"prediction: {0}\\nlabel:{1}\".format(incorrect_prediction, get_class(example)))\n",
        "   for (example, incorrect_prediction) in incorrect[:20]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YN_s04Il8TvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercises: Improve the model!\n",
        "\n",
        "We've trained a baseline model, now let's try to improve it to achieve better accuracy. (Remember that you'll need to re-run the cells when you make a change.)\n",
        "\n",
        "### Exercise 1:  Try a different image model.\n",
        "With TF-Hub, trying a few different image models is simple. Just replace the `\"https://tfhub.dev/google/imagenet/mobilenet_v2_050_128/feature_vector/2\"` handle in the `hub.Module()` call with a handle of different module and rerun all the code. You can see all available image modules at [tfhub.dev](https://alpha.tfhub.dev/s?MODULETYPES=image-feature-vector). \n",
        "\n",
        "A good choice might be one of the other [MobileNet V2 modules](https://alpha.tfhub.dev/s?module-type=image-feature-vector&network-architecture=mobilenet-v2). Many of the modules -- including the MobileNet modules -- were trained on the [ImageNet dataset](http://image-net.org/challenges/LSVRC/2012/index#task) which contains over 1 million images and 1000 classes. Choosing a network architecture provides a tradeoff between speed and classification accuracy: models like MobileNet or NASNet Mobile are fast and small, more traditional architectures like Inception and ResNet were designed for accuracy.\n",
        "\n",
        "For the larger Inception V3 architecture, you can also explore the benefits of pre-training on a domain closer to your own task: it is also available as a [module trained on the iNaturalist dataset](https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/1) of plants and animals.\n",
        "\n",
        "### Exercise 2: Add a hidden layer.\n",
        "Stack a hidden layer between extracted image features and the linear classifier (in function `create_model()` above). To create a non-linear hidden layer with e.g. 100 nodes, use  [tf.layers.dense](https://www.tensorflow.org/api_docs/python/tf/layers/dense) with units set to 100 and activation set to `tf.nn.relu`. Does changing the size of the hidden layer affect the test accuracy? Does adding second hidden layer improve the accuracy?\n",
        "\n",
        "### Exercise 3: Change hyperparameters.\n",
        "Does increasing  *number of training steps*  improves final accuracy? Can you *change the learning rate* to make your model converge more quickly? Does the training *batch size* affect your model's performance?\n",
        "\n",
        "### Exercise 4: Try a different optimizer.\n",
        "\n",
        "Replace the basic GradientDescentOptimizer with a more sophisticate [optimizer](https://www.tensorflow.org/api_guides/python/train#Optimizers), e.g.  [AdagradOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer). Does it make a difference to your model training? If you want to learn more about the benefits of different optimization algorithms, check out [this post](http://ruder.io/optimizing-gradient-descent/)."
      ]
    },
    {
      "metadata": {
        "id": "kdwVXO1eJS5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Want to learn more?\n",
        "\n",
        "If you are interested in a more advanced version of this tutorial, check out the [TensorFlow image retraining tutorial](https://www.tensorflow.org/hub/tutorials/image_retraining) which walks you through visualizing the training using TensorBoard, advanced techniques like dataset augmentation by distorting images, and replacing the flowers dataset to learn an image classifier on your own dataset.\n",
        "\n",
        "You can learn more about TensorFlow at [tensorflow.org](http://tensorflow.org) and see the TF-Hub API documentation is available at [tensorflow.org/hub](https://www.tensorflow.org/hub/). Find available TensorFlow Hub modules at [tfhub.dev](http://tfhub.dev) including more image feature vector modules and text embedding modules.\n",
        "\n",
        "Also check out the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/) which is Google's fast-paced, practical introduction to machine learning."
      ]
    }
  ]
}