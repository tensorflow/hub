# Module google/&zwnj;imagenet/&zwnj;resnet_v2_101/&zwnj;classification/1
Imagenet (ILSVRC-2012-CLS) classification with ResNet V2 101.

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- module-type: image-classification -->
<!-- network-architecture: ResNet V2 101 -->

**Module URL:** [https://tfhub.dev/google/imagenet/resnet_v2_101/classification/1](https://tfhub.dev/google/imagenet/resnet_v2_101/classification/1)

## Overview

ResNet V2 is a family of network architectures for image classification
with a variable number of layers. It builds on the ResNet architecture
originally published by

  * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun: ["Deep Residual Learning
    for Image Recognition"](https://arxiv.org/abs/1512.03385), 2015.

The full preactivation 'V2' variant of ResNet used in this module was
introduced by

  * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun: ["Identity Mappings in
    Deep Residual Networks"](https://arxiv.org/abs/1603.05027), 2016.

The key difference compared to ResNet V1 is the use of batch normalization
before every weight layer.

This TF-Hub module uses the TF-Slim implementation of `resnet_v2_101`
with 101 layers.
The module contains a trained instance of the network, packaged to do the
[image classification](../../../../../common_signatures/images.md#classification)
that the network was trained on. If you merely want to transform images into
feature vectors, use module
[`google/imagenet/resnet_v2_101/feature_vector/1`](../feature_vector/1.md)
instead, and save the space occupied by the classification layer.


## Training

The checkpoint exported into this module was `resnet_v2_101_2017_04_14/resnet_v2_101.ckpt` downloaded
from
[TF-Slim's pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/README.md#pre-trained-models).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet").


## Usage

This module implements the common signature for 
[image classification](../../../../../common_signatures/images.md#classification).
It can be used like

```python
module = hub.Module("https://tfhub.dev/google/imagenet/resnet_v2_101/classification/1")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
logits = module(images)  # Logits with shape [batch_size, num_classes].
```

...or using the signature name `image_classification`. The indices into logits
are the `num_classes` = 1001 classes of the classification from
the original training (see above).

This module can also be used to compute [image feature
vectors](../../../../../common_signatures/images.md#feature-vector),
using the signature name `image_feature_vector`.

For this module, the size of the input image is fixed to
`height` x `width` = 224 x 224 pixels.
The input `images` are expected to have color values in the range [0,1],
following the
[common image input](../../../../../common_signatures/images.md#input)
conventions.


## Fine-tuning

In principle, consumers of this module can
[fine-tune](../../../../../fine_tuning.md) it.
However, fine-tuning through a large classification might be prone to overfit.

Fine-tuning requires importing the graph version with tag set `{"train"}`
in order to operate batch normalization in training mode.

