# Lite sayakpaul/east-text-detector/fp16/1
TF Lite quantized version of the CartoonGAN model for cartoonizing images. 

<!-- parent-model: sayakpaul/cartoongan/1 -->
<!-- asset-path: https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite/releases/download/v0.7.0/whitebox_cartoon_gan_fp16.tar.gz -->

[![Open Colab notebook]](https://colab.research.google.com/github/margaretmz/CartoonGAN-e2e-tflite-tutorial/blob/master/ml/CartoonGAN_TFLite_Fixed_Shaped.ipynb)

### Overview
This variant of CartoonGAN model was proposed in [1]. The model can take an input image (preferably natural images) and cartoonize it in a way such that the resultant image is visually and semantically pleasing. Here is an example result - 

![](https://i.ibb.co/wyB38YV/image.png)

### Note
- This model was quantized using `float16` quantization as described [here](https://www.tensorflow.org/lite/performance/post_training_float16_quant).
- This model is populated with metadata. 
- This model takes fixed-shaped (224x224) inputs (images with BGR channel ordering). 
- The Colab Notebook that accompanies the model contains conversion and inference steps. 
- The model currently does not run on TFLite GPU Delegate and this is a known limitation. We recommend using the dynamic range and `int8` quantized models if you are looking for speed as well as good results. 

### Example use
For a good understanding of the model usage keep an eye out on (this repo)[https://github.com/margaretmz/CartoonGAN-e2e-tflite-tutorial].

### Acknowledgements
Thanks to Margaret Maynard-Reid and Khanh LeViet for their constant guidance.

References
--------------
[1] Learning to Cartoonize Using White-Box Cartoon Representations. Xinrui Wang, Jinze Yu; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 8090-8099.