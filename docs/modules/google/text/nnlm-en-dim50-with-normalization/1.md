# Module google/text/nnlm-en-dim50-with-normalization/1
Token based text embedding trained on English Google News 7B corpus.

**Module URL:** https://storage.googleapis.com/tfhub-test-modules/google/text/nnlm-en-dim50-with-normalization/1.tar.gz

## Overview

Text embedding based on feed-forward Neural-Net Language Models (NN-LM) with
pre-built OOV. Maps from text to 50-dimensional embedding vectors.

#### Example use
```
embed = hub.Module("https://storage.googleapis.com/tfhub-test-modules/google/text/nnlm-en-dim50-with-normalization/1.tar.gz")
embeddings = embed(["cat is on the mat", "dog is in the fog"])
```

## Details
Based on NNLM with two hidden layers.

#### Input
The module takes **a batch of sentences in a 1-D tensor of strings** as input.

#### Preprocessing
The module preprocesses its input by **removing punctuation and splitting on spaces**.

#### Out of vocabulary tokens
Small fraction of the least frequent tokens and embeddings (~2.5%) are
**replaced by hash buckets**. Each has bucket is initialized using the remaining
embedding vectors that hash to the same bucket.
