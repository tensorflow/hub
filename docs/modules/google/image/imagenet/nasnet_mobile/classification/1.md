# Module google/image/imagenet/nasnet_mobile/classification/1

**Module URL:** https://storage.googleapis.com/tfhub-test-modules/google/image/imagenet/nasnet_mobile/classification/1.tar.gz

## Overview

NASNet is a family of convolutional neural networks for image classification.
The architecture of its convolutional cells (or layers) has been found by
Neural Architecture Search (NAS). NAS and NASNet were originally published by

  * Barret Zoph, Quoc V. Le: ["Neural Architecture Search
    with Reinforcement Learning"](https://arxiv.org/abs/1611.01578), 2017.
  * Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V. Le:
    ["Learning Transferable Architectures for Scalable Image
    Recognition"](https://arxiv.org/abs/1707.07012), 2017.

NASNets come in various sizes. This TF-Hub module uses the TF-Slim
implementation of `nasnet_mobile` for ImageNet
that uses 12 Normal Cells,
starting with 44 convolutional filters.
It has a default input size of 224x224 pixels.

The module contains a trained instance of the network, packaged to do
the [image classification](https://github.com/tensorflow/hub/blob/master/docs/common_signatures/images.md#image-classification)
that the network was trained on. If you merely want to transform images into
feature vectors, use module
[`google/image/imagenet/nasnet_mobile/feature_vector/1`](../feature_vector/1.md)
instead, and save the space occupied by the classification layer.


## Training

The checkpoint exported into this module was `nasnet-a_mobile_04_10_2017/model.ckpt` downloaded
from
[NASNet's pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/README.md).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("ImageNet").

## Usage

This module implements the common signature for 
[image classification](https://github.com/tensorflow/hub/blob/master/docs/common_signatures/images.md#image-classification).
It can be used like

```python
images = ...  # A batch of images with shape [batch_size, height, width, 3].
module = hub.Module("https://storage.googleapis.com/tfhub-test-modules/google/image/imagenet/nasnet_mobile/classification/1.tar.gz")
logits = module(images)  # Logits with shape [batch_size, num_classes].
```

...or using the signature name `image_classification`. The indices into logits
are the classes of the classification from the original training (see above).

This module can also be used to compute [image feature
vectors](https://github.com/tensorflow/hub/blob/master/docs/common_signatures/images.md#image-feature-vector),
using the signature name `image_feature_vector`.

The input `images` are expected to have color values in the range [0,1],
following the [common image input](https://github.com/tensorflow/hub/blob/master/docs/common_signatures/images.md#image-input)
conventions. The default image size for this module is
224x224 pixels.


## Fine-tuning

In principle, consumers of this module can
[fine-tune](https://github.com/tensorflow/hub/blob/master/README.md#fine-tuning)
it. However, fine-tuning through a large classification might be prone to
overfit.

Fine-tuning requires to import the graph version with tag set `["train"]`
in order to operate batch normalization and dropout in training mode.
The dropout probability in NASNet's path dropout is not scaled with
the training steps of fine-tuning and remains at the final (maximal) value
from the initial training.

